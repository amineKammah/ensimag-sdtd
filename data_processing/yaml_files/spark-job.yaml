apiVersion: batch/v1
kind: Job
metadata:
  name: ocr-service
spec:
  template:
    spec:
      containers:
        - name: spark
          image: kammahm/sdtd_data_processing:latest
          command: [
            "/bin/sh",
            "-c",
            "git pull && /opt/spark/bin/spark-submit \
             --master k8s://https://#K8S_MASTER#:6443 \
            --deploy-mode cluster \
            --name data_processing \
            --conf spark.kubernetes.driver.volumes.persistentVolumeClaim.checkpointpvc.mount.path=/checkpoint \
            --conf spark.kubernetes.driver.volumes.persistentVolumeClaim.checkpointpvc.mount.readOnly=false \
            --conf spark.kubernetes.driver.volumes.persistentVolumeClaim.checkpointpvc.options.claimName=spark-pvc-claim \
            --conf spark.kubernetes.driver.job.backofflimit=5 \
            --conf spark.kubernetes.container.image=kammahm/sdtd_data_processing:latest \
            --conf spark.kubernetes.container.image.pullPolicy=Always \
            --conf spark.executor.instances=2 \
            --conf spark.executor.cores=1 \
            --conf spark.kubernetes.authenticate.driver.serviceAccountName=spark \
            --conf spark.kubernetes.driverEnv.KAFKA_SERVER1='kaf1:9092' \
            --conf spark.kubernetes.driverEnv.KAFKA_SERVER2='kaf2:9092' \
            --conf spark.kubernetes.driverEnv.ZK_SERVER1='zoo1:2181' \
            --conf spark.kubernetes.driverEnv.ZK_SERVER2='zoo2:2181' \
            --conf spark.kubernetes.driverEnv.K8S_MASTER='#K8S_MASTER#' \
            --conf spark.scheduler.mode='FAIR' \
            --conf spark.streaming.concurrentjobs=6 \
            --conf spark.locality.wait='0s' \
            --jars '/opt/spark/spark-streaming-kafka-0-8-assembly_2.11-2.4.4.jar' \
            local:///ensimag-sdtd/run_ocr_service.py "
          ]
      serviceAccountName: spark
      restartPolicy: OnFailure
  backoffLimit: 4
